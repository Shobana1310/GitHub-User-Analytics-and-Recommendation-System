{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import pymongo\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "from github3 import GitHub\n",
    "import github3\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key =os.getenv(\"github_api_key_2\")\n",
    "headers = {\"Authorization\": f\"token {api_key}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_details(user_name):\n",
    "       user_url = f'https://api.github.com/users/{user_name}'\n",
    "       response = requests.get(user_url, headers=headers)\n",
    "       user_json= response.json()\n",
    "       starred_url = user_json['starred_url'].replace('{/owner}{/repo}', '')\n",
    "       response = requests.get(starred_url)\n",
    "       star_list=[]\n",
    "       if response.status_code == 200:\n",
    "            starred_repos = response.json()\n",
    "            for repo in starred_repos:\n",
    "                star_list.append(repo['full_name'])\n",
    "       else:\n",
    "            print(\"Failed to fetch starred repositories. Status code:\", response.status_code)\n",
    "       if not star_list:\n",
    "           star_list = None\n",
    "       data_list=[{\n",
    "              'login':user_json['login'],\n",
    "              'name':user_json['name'],\n",
    "              'bio':user_json['bio'],\n",
    "              'company':user_json['company'],\n",
    "              'location':user_json['location'],\n",
    "              'company':user_json['company'],\n",
    "              'email':user_json['email'],\n",
    "              'public_repos':user_json['public_repos'],\n",
    "              'following_count':user_json['following'],\n",
    "              'followers_count':user_json['followers'],\n",
    "              'created_at':user_json['created_at'],\n",
    "              'avatar_url':user_json['avatar_url'],\n",
    "              'profile_url':user_json['html_url'],\n",
    "       }]\n",
    "       if star_list is not None:\n",
    "           data_list[0]['user_starred_repo'] = ','.join(star_list)\n",
    "       else:\n",
    "           data_list[0]['user_starred_repo'] = None\n",
    "       return data_list\n",
    "\n",
    "#get_user_details('navinds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_repository_readme(repo_full_name):\n",
    "    repo_url = f\"https://github.com/{repo_full_name}\"\n",
    "    response = requests.get(repo_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        readme_section = soup.find('article', class_='markdown-body')\n",
    "        if readme_section:\n",
    "            text = readme_section.get_text(separator=' ')\n",
    "            \n",
    "            \n",
    "            text = re.sub(r'http\\S+', '', text)\n",
    "            text = re.sub(r'#+|\\*{1,3}', '', text)\n",
    "            text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "            text = re.sub(r'\\d', '', text)\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            text = re.sub(r'\\[.*?\\]', '', text)\n",
    "            \n",
    "            lines = text.split(' ')\n",
    "            cleaned_lines = []\n",
    "            for line in lines:\n",
    "                if not re.search(r'\\([^\\)]+\\)\\s*[-â€”]\\s*\\w+', line):\n",
    "                    cleaned_lines.append(line)\n",
    "            cleaned_text = ' '.join(cleaned_lines).strip()\n",
    "            \n",
    "            if len(cleaned_text) > 3000:\n",
    "                cleaned_text = cleaned_text[:3000]\n",
    "            \n",
    "            return cleaned_text\n",
    "        else:\n",
    "            print(f\"README not found for repository: {repo_full_name}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to fetch repository: {repo_full_name}\")\n",
    "        return None\n",
    "\n",
    "def get_all_repos(user_name):\n",
    "    user_repos_url = f\"https://api.github.com/users/{user_name}/repos\"\n",
    "    repos = []\n",
    "    page = 1\n",
    "    per_page = 100 \n",
    "\n",
    "    while True:\n",
    "        params = {'page': page, 'per_page': per_page}\n",
    "        response = requests.get(user_repos_url, params=params)\n",
    "        \n",
    "        if response.status_code == 403:  # Rate limit error\n",
    "            reset_time = int(response.headers.get('X-RateLimit-Reset'))\n",
    "            sleep_time = reset_time - int(time.time()) + 5  \n",
    "            time.sleep(sleep_time)\n",
    "            continue\n",
    "        \n",
    "        response_json = response.json()\n",
    "        \n",
    "        if not response_json:\n",
    "            break\n",
    "        \n",
    "        repos.extend(response_json)\n",
    "        page += 1\n",
    "    \n",
    "    return repos\n",
    "\n",
    "def get_all_readme_details(user_name):\n",
    "    user_repos = get_all_repos(user_name)\n",
    "    readme_data = []\n",
    "\n",
    "    for repo in user_repos:\n",
    "        repo_full_name = repo['full_name']\n",
    "        readme = scrape_repository_readme(repo_full_name)\n",
    "\n",
    "        if readme is not None:\n",
    "            readme_data.append({\n",
    "                'login': user_name,\n",
    "                'repos_name': repo[\"name\"],\n",
    "                'repo_url': repo[\"html_url\"],\n",
    "                'readme': readme\n",
    "            })\n",
    "    \n",
    "    return readme_data\n",
    "\n",
    "# Example usage:\n",
    "#readme_details = get_all_readme_details('armjscom')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_repository_details(repo):\n",
    "    commits_count = 0\n",
    "    commits_url = repo['commits_url'].replace('{/sha}', '') \n",
    "    response = requests.get(commits_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        commits_count = len(response.json())\n",
    "\n",
    "    language_url = repo['languages_url']\n",
    "    response = requests.get(language_url, headers=headers)\n",
    "    languages_used = \"\"\n",
    "    languages_list = []  # Initialize languages_list here\n",
    "    if response.status_code == 200:\n",
    "        languages_data = response.json()\n",
    "        languages_list = list(languages_data.keys())\n",
    "        languages_used = ','.join([f\"{lang} ({languages_data[lang]})\" for lang in languages_list])\n",
    "\n",
    "    return commits_count, languages_used, languages_list\n",
    "\n",
    "def get_all_repository_details(user_name):\n",
    "    \n",
    "    user_url = f'https://api.github.com/users/{user_name}'\n",
    "    response = requests.get(user_url, headers=headers)\n",
    "    user_json = response.json()\n",
    "    repos_url = user_json['repos_url']\n",
    "    \n",
    "    repository_data = []\n",
    "    page = 1\n",
    "    per_page = 100  \n",
    "   \n",
    "    while True:\n",
    "       \n",
    "        params = {'page': page, 'per_page': per_page}\n",
    "        response = requests.get(repos_url, headers=headers, params=params)\n",
    "        response_json = response.json()\n",
    "        \n",
    "        if not response_json:\n",
    "            break\n",
    "        \n",
    "        for repo in response_json:\n",
    "            commits_count, languages_used, languages_list = fetch_repository_details(repo)\n",
    "            \n",
    "            repository_data.append({\n",
    "                'login': repo['owner']['login'],\n",
    "                'repo_id': repo['id'],\n",
    "                'repos_name': repo[\"name\"],\n",
    "                'Language_used': repo['language'],\n",
    "                'repo_url': repo[\"html_url\"],\n",
    "                'pushed_at': repo['pushed_at'],\n",
    "                'size': repo['size'],\n",
    "                'repos_description': repo[\"description\"],\n",
    "                'repo_created_at': repo[\"created_at\"],\n",
    "                'languages_with_count': languages_used,\n",
    "                'languages_list': ' '.join(languages_list),\n",
    "                'forks_count': repo[\"forks_count\"],\n",
    "                'open_issues_count': repo[\"open_issues\"],\n",
    "                'updated_at': repo['updated_at'],\n",
    "                'Stargazers': repo['stargazers_count'],\n",
    "                'Watchers_Counts': repo['watchers_count'],\n",
    "                'commit_count': commits_count\n",
    "            })\n",
    "        \n",
    "        page += 1\n",
    "    \n",
    "    return repository_data\n",
    "\n",
    "# repository_details=get_all_repository_details('krishnaik06')\n",
    "# repository_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "mongo_atlas_user_name = os.getenv(\"MONGO_ATLAS_USER_NAME\") \n",
    "mongo_atlas_password =  os.getenv(\"MONGO_ATLAS_PASSWORD\") \n",
    "client=pymongo.MongoClient(f\"mongodb+srv://{mongo_atlas_user_name}:{mongo_atlas_password}@cluster0.ehfepgy.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db = client[\"github\"]\n",
    "collection=db[\"github_user_details\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_detailsof_user(user_name):\n",
    "    try:\n",
    "        user=get_user_details(user_name)\n",
    "        repository=get_all_repository_details(user_name)\n",
    "        readme=get_all_readme_details(user_name)\n",
    "        collection.insert_one({\n",
    "                'user_data': user,\n",
    "                'repository_data': repository,\n",
    "                'readme_data':readme})\n",
    "        print(f\"Data inserted for user: {user_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process user {user_name}. Error: {e}\")\n",
    "#get_all_detailsof_user('Python-Repository-Hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_detailsof_user(user_name):\n",
    "    try:\n",
    "        # Get the new cleaned readme details\n",
    "        readme = get_all_readme_details(user_name)  # Assume this now gets cleaned data\n",
    "\n",
    "        # Update the readme_data field\n",
    "        collection.update_one(\n",
    "            {'user_data.login': user_name},\n",
    "            {'$set': {'readme_data': readme}}\n",
    "        )\n",
    "\n",
    "        print(f\"Readme data updated for user: {user_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process user {user_name}. Error: {e}\")\n",
    "\n",
    "\n",
    "#get_all_detailsof_user('charliecalvert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_all_detailsof_user(user_name):\n",
    "  try:\n",
    "    user = get_user_details(user_name)\n",
    "    repository = get_all_repository_details(user_name)\n",
    "    readme=get_all_readme_details(user_name)\n",
    "\n",
    "    collection.update_one(\n",
    "        {'user_name': user_name},  \n",
    "        {'$set': {'user_data': user, 'repository_data': repository,'readme_data':readme}},  # Update details\n",
    "        upsert=True)  \n",
    "\n",
    "    print(f\"Data updated for user: {user_name}\")\n",
    "  except Exception as e:\n",
    "    print(f\"Failed to update user {user_name}. Error: {e}\")\n",
    "#update_all_detailsof_user('Shobana1310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README not found for repository: nskumara/AlgoAprioriPython\n",
      "README not found for repository: nskumara/Assignment3_CV\n",
      "README not found for repository: nskumara/Assignment_2_Flex\n",
      "README not found for repository: nskumara/Assignment_2_Float\n",
      "README not found for repository: nskumara/Disaster_Preparedness\n",
      "README not found for repository: nskumara/Disaster_Preparedness2\n",
      "README not found for repository: nskumara/Disaster_Preparedness_in_Japan\n",
      "README not found for repository: nskumara/Leadership_Project_Group_18\n",
      "README not found for repository: nskumara/Sri_Lanka2\n",
      "README not found for repository: nskumara/Web_Final_Project\n",
      "README not found for repository: nskumara/Web_Final_Project_1\n",
      "README not found for repository: nskumara/Welcome_to_Sri_Lanka\n",
      "Readme data updated for user: nskumara\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import github3\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import httpx\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "logging.basicConfig(filename='data_collection.log', level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "\n",
    "\n",
    "api_keys = [os.getenv(f\"github_api_key_{i}\") for i in range(1, 6)]\n",
    "current_key_index = 0\n",
    "api_keys_lock = asyncio.Lock()\n",
    "\n",
    "def initialize_github_client():\n",
    "    return github3.login(token=api_keys[current_key_index])\n",
    "\n",
    "gh = initialize_github_client()\n",
    "\n",
    "async def switch_github_client():\n",
    "    global current_key_index\n",
    "    async with api_keys_lock:\n",
    "        current_key_index = (current_key_index + 1) % len(api_keys)\n",
    "        new_client = github3.login(token=api_keys[current_key_index])\n",
    "        logging.info(f\"Switched to API key index {current_key_index}\")\n",
    "        return new_client\n",
    "\n",
    "async def fetch_user_details(client, user_name, retries=3, backoff_factor=0.3):\n",
    "    global gh\n",
    "    try:\n",
    "        url = f\"https://api.github.com/users/{user_name}\"\n",
    "        headers = {\n",
    "            'Authorization': f'token {api_keys[current_key_index]}',\n",
    "            'Accept': 'application/vnd.github.v3+json'\n",
    "        }\n",
    "        for attempt in range(retries):\n",
    "            response = await client.get(url, headers=headers)\n",
    "            if response.status_code == 404:\n",
    "                logging.warning(f\"User {user_name} not found.\")\n",
    "                return\n",
    "            elif response.status_code == 403 and 'X-RateLimit-Remaining' in response.headers and int(response.headers['X-RateLimit-Remaining']) == 0:\n",
    "                logging.warning(\"Rate limit exceeded. Switching API key and retrying...\")\n",
    "                gh = await switch_github_client()\n",
    "                headers['Authorization'] = f'token {api_keys[current_key_index]}'\n",
    "                await asyncio.sleep(backoff_factor * (2 ** attempt))\n",
    "                continue\n",
    "            elif response.status_code != 200:\n",
    "                logging.error(f\"Error fetching user {user_name}: {response.status_code}\")\n",
    "                await asyncio.sleep(backoff_factor * (2 ** attempt))\n",
    "                continue\n",
    "            user_data = response.json()\n",
    "            # Replace with actual processing of user_data\n",
    "            get_all_detailsof_user(user_name)  \n",
    "            logging.info(f\"Processed user: {user_name}\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception while fetching user {user_name}: {e}\")\n",
    "\n",
    "async def process_user_batch(usernames):\n",
    "    async with httpx.AsyncClient(http2=True) as client:\n",
    "        tasks = [fetch_user_details(client, user_name) for user_name in usernames]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "async def proactive_rate_limit_check():\n",
    "    global gh  \n",
    "    while True:\n",
    "        rate_limit = gh.rate_limit()['rate']\n",
    "        remaining = rate_limit['remaining']\n",
    "        if remaining < 10: \n",
    "            logging.info(\"Proactively switching API key due to low remaining requests.\")\n",
    "            gh = await switch_github_client()\n",
    "        await asyncio.sleep(5) \n",
    "\n",
    "async def push_users_to_mongodb(usernames, batch_size):\n",
    "    collected_usernames = set()\n",
    "    batch_number = 1\n",
    "    for i in range(0, len(usernames), batch_size):\n",
    "        batch_usernames = usernames[i:i+batch_size]\n",
    "        await process_user_batch(batch_usernames)\n",
    "        logging.info(f\"Batch {batch_number} processed.\")\n",
    "        batch_number += 1\n",
    "\n",
    "async def main():\n",
    "    usernames = [\"nskumara\"]\n",
    "\n",
    "    batch_size = 3  # Adjust the batch size as necessary\n",
    "    logging.info(f\"Processing users: {usernames}\")\n",
    "    \n",
    "    rate_limit_task = asyncio.create_task(proactive_rate_limit_check())\n",
    "    await push_users_to_mongodb(usernames, batch_size)\n",
    "    rate_limit_task.cancel()\n",
    "\n",
    "\n",
    "def run():\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            asyncio.ensure_future(main())\n",
    "        else:\n",
    "            loop.run_until_complete(main())\n",
    "    except RuntimeError:\n",
    "        new_loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(new_loop)\n",
    "        new_loop.run_until_complete(main())\n",
    "\n",
    "run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key =os.getenv(\"github_api_key_3\")\n",
    "gh = github3.login(token=api_key)\n",
    "\n",
    "def collect_usernames_by_keyword(keyword, batch_size):\n",
    "    usernames = [] \n",
    "    search_results = gh.search_users(keyword)\n",
    "    count = 0\n",
    "    for user in search_results:\n",
    "        usernames.append(user.login)\n",
    "        count += 1\n",
    "        if count >= batch_size:\n",
    "            break\n",
    "    return usernames\n",
    "\n",
    "keyword = 'Data scientist'  \n",
    "batch_size = 500\n",
    "usernames = collect_usernames_by_keyword(keyword, batch_size)\n",
    "for user_name in usernames:\n",
    "    print(user_name)\n",
    "  \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
